
#include <iostream>
#include <sstream>
#include <iomanip>
#include <memory>
#include <list>

#include <VX/vx.h>
#include <NVX/nvx_timer.hpp>

#include "NVXIO/FrameSource.hpp"
#include "NVXIO/Render.hpp"
#include "NVXIO/Application.hpp"
#include "NVXIO/Utility.hpp"

#include "iterative_motion_estimator.hpp"

struct EventData
{
    EventData(): alive(true), pause(false) {}

    bool alive;
    bool pause;
};

static void keyboardEventCallback(void* context, vx_char key, vx_uint32 /*x*/, vx_uint32 /*y*/)
{
    EventData* eventData = static_cast<EventData*>(context);
    if (key == 27) // escape
    {
        eventData->alive = false;
    }
    else if (key == 32)
    {
        eventData->pause = !eventData->pause;
    }
}


int main(int argc, char** argv)
{
    std::cout << "Hello World" << std::endl;

    nvxio::Application &app = nvxio::Application::get();

    nvxio::FrameSource::Parameters config;
    config.frameWidth = 2592;  // 1280;
    config.frameHeight = 1458; // 720;
    config.fps = 30;

    app.init(argc, argv);
    std::list<std::function<void(void)>> callAtExit;

    //
    // Create OpenVX context
    //

    nvxio::ContextGuard context;
  
    //
    // Messages generated by the OpenVX framework will be processed by nvxio::stdoutLogCallback
    //
    vxRegisterLogCallback(context, &nvxio::stdoutLogCallback, vx_false_e);



    //
    // Source
    //
    std::string resolution = "1280x720", input = "device:///nvcamera";
    auto source = nvxio::createDefaultFrameSource(context, input);
    if (!source) {
        std::cout << "Error: cannot open source!" << std::endl;
        return nvxio::Application::APP_EXIT_CODE_NO_RESOURCE;
    }

    if (!source->setConfiguration(config)){
        std::cout << "Error: cannot setup configuration the framesource!" << std::endl;
        return nvxio::Application::APP_EXIT_CODE_INVALID_VALUE;
    }

    if (!source->open()) {
        std::cout << "Error: cannot open source!" << std::endl;
        return nvxio::Application::APP_EXIT_CODE_NO_RESOURCE;
    }
    config = source->getConfiguration();

    vx_image fullResImage = vxCreateImage(context, config.frameWidth, config.frameHeight, config.format /*VX_DF_IMAGE_RGBX*/);
    NVXIO_CHECK_REFERENCE(fullResImage);
    callAtExit.push_back([&]() { vxReleaseImage(&fullResImage);});

    auto w = (config.frameWidth + 1) / 2;
    auto h = (config.frameHeight + 1) / 2;

    vx_image tmpImage = vxCreateImage(context, w, h, config.format /*VX_DF_IMAGE_RGBX*/);
    NVXIO_CHECK_REFERENCE(tmpImage);

    //
    // Create a Render
    //
    //auto render = nvxio::createDefaultRender(context, "NVIDIA GStreamer Camera Capture Sample", config.frameWidth, config.frameHeight);
    auto render = nvxio::createWindowRender(context, "NVIDIA GStreamer Camera Capture Sample", w, h);
    if (!render)
    {
        std::cout << "Error: Cannot open default render!" << std::endl;
        return nvxio::Application::APP_EXIT_CODE_NO_RENDER;
    }

    EventData eventData;
    render->setOnKeyboardEventCallback(keyboardEventCallback, &eventData);

    //vx_image frame = vxCreateImage(context, config.frameWidth, config.frameHeight, config.format);
    //NVXIO_CHECK_REFERENCE(frame);

    //
    // Create OpenVX Image to hold frames from video source
    //
    vx_image frameExemplar = vxCreateImage(context, w, h, config.format /*VX_DF_IMAGE_RGBX*/);
    NVXIO_CHECK_REFERENCE(frameExemplar);

    size_t nbFrameDelay = 2;
    vx_delay frame_delay = vxCreateDelay(context, (vx_reference)frameExemplar, nbFrameDelay);
    NVXIO_CHECK_REFERENCE(frame_delay);
    vxReleaseImage(&frameExemplar);
    callAtExit.push_back([&]() { vxReleaseDelay(&frame_delay);});

    vx_image prevFrame = (vx_image)vxGetReferenceFromDelay(frame_delay, -nbFrameDelay + 1);
    vx_image currFrame = (vx_image)vxGetReferenceFromDelay(frame_delay, 0);

    // Create a remap object
    auto swapRemap = vxCreateRemap(context,w,h,w,h);
    NVXIO_CHECK_REFERENCE(swapRemap);
    for (auto y = 0; y < h; y++)
        for (auto x = 0; x < w; x++)
            if (VX_SUCCESS  != vxSetRemapPoint(swapRemap, x, y, w - x - 1, h - y - 1))
                std::cout << "vxSetRemapPoint failed" << std::endl;
    callAtExit.push_back([&]() { vxReleaseRemap(&swapRemap);});

    // Color Convert
    vx_image frame_gray = vxCreateImage(context, w, h, VX_DF_IMAGE_U8);
    NVXIO_CHECK_REFERENCE(frame_gray);
    callAtExit.push_back([&]() { vxReleaseImage(&frame_gray);});

    vx_image frame_gray2 = vxCreateImage(context, w, h, VX_DF_IMAGE_U8);
    NVXIO_CHECK_REFERENCE(frame_gray2);
    callAtExit.push_back([&]() { vxReleaseImage(&frame_gray2);});
 

    IterativeMotionEstimator ime(context);

    //
    // Create algorithm
    //
    IterativeMotionEstimator::Params params;

    nvxio::Render::TextBoxStyle style = {{255, 255, 255, 255}, {0, 0, 0, 127}, {10, 10}};

    nvx::Timer totalTimer;
    totalTimer.tic();

    // auto syncTimer = nvxio::createSyncTimer();
    // syncTimer->arm(1. / app.getFPSLimit());

    size_t loopCnt{0};
    while (eventData.alive)
    {
        ++loopCnt;
        nvxio::FrameSource::FrameStatus status = nvxio::FrameSource::OK;
        if (!eventData.pause)
        {
            status = source->fetch(fullResImage);
        }

        switch (status)
        {
        case nvxio::FrameSource::TIMEOUT:
            continue;
        case nvxio::FrameSource::CLOSED:
            eventData.alive = false;
            break;
        case nvxio::FrameSource::OK:
        {
            vx_status status;
            NVXIO_SAFE_CALL(vxuScaleImage(context, fullResImage, currFrame, VX_INTERPOLATION_TYPE_BILINEAR));

            if (loopCnt < nbFrameDelay)
                continue; // this will fill the delay Q.
            else if (loopCnt == nbFrameDelay)
            {
                IterativeMotionEstimator::Params params;
                params.biasWeight = 10.0f; // 1.0f
                params.mvDivFactor = 4;
                params.smoothnessFactor = 1.0f; 
                ime.init(prevFrame, currFrame, params); // todo handle wrap around of loopCnt
            }

            double total_ms = totalTimer.toc();
            totalTimer.tic();

            std::ostringstream txt;
            txt << std::fixed << std::setprecision(1);

            txt << "Camera mode: " << config.frameWidth << 'x' << config.frameHeight << ' ' << config.fps << " FPS" << std::endl;
            txt << "Algorithm: "
                << "No Processing" << std::endl;
            txt << "Display: " << total_ms << " ms / " << 1000.0 / total_ms << " FPS" << std::endl;

            txt << std::setprecision(6);
            txt.unsetf(std::ios_base::floatfield);

            txt << "FRAME RATE IS NOT CONSTRAINED" << std::endl;

            std::cout << txt.str();

            txt << "Space - pause/resume" << std::endl;
            txt << "Esc - close the demo";

            ime.process();

            NVXIO_SAFE_CALL(vxuColorConvert(context, prevFrame, frame_gray));

            NVXIO_SAFE_CALL(vxuRemap(context, frame_gray, swapRemap, VX_INTERPOLATION_TYPE_NEAREST_NEIGHBOR, frame_gray2));

            render->putImage(frame_gray);
            //render->putImage(frame_gray2);

            render->putTextViewport(txt.str(), style);

            nvxio::Render::MotionFieldStyle mfStyle = {
                {0u, 255u, 255u, 255u} // color
            };

            render->putMotionField(ime.getMotionField(), mfStyle);

            if (!render->flush())
                eventData.alive = false;

            if (!eventData.pause)
            {
                vxAgeDelay(frame_delay);
            }
        }
        break;
        }
    }

    //
    // Release all objects
    //
    for(auto& it: callAtExit) it();

    return nvxio::Application::APP_EXIT_CODE_SUCCESS;
}


